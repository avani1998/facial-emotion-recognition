{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4253cd1-5e14-43ec-a596-788bf5158800"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.utils  import plot_model\n",
        "from collections  import Counter\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "id": "c4253cd1-5e14-43ec-a596-788bf5158800",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d2d0709-adfd-40c2-9c1c-10168755d03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3d098df0-cd3f-43fe-9e4d-d1051d07e747"
      },
      "source": [
        "\n",
        "df=pd.read_csv('legend.csv') #read into data frame\n",
        "\n",
        "df.drop(columns=\"user.id\", inplace=True) #drop the userid col, since it is not used\n",
        "df['emotion'] = df['emotion'].str.lower() #make all the labels lowercase\n",
        "\n",
        "valid_df = df.sample(frac=0.1) #randomly sample 10% of the data to use as validation data\n",
        "train_df = df[~df['image'].isin(valid_df['image'])] #delete validation data from training data\n",
        "\n",
        "test_df = train_df.sample(frac=0.05) #randomly 5% sample remaining data to use as test data, since no other test data exist now\n",
        "train_df = train_df[~train_df['image'].isin(test_df['image'])] #delete test data from training data"
      ],
      "id": "7d2d0709-adfd-40c2-9c1c-10168755d03b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-847657a8b5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'legend.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#read into data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"user.id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#drop the userid col, since it is not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#make all the labels lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "051qsXshfOrS"
      },
      "id": "051qsXshfOrS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "35828191-fd6a-4229-9eb7-0906d23a1916",
        "outputId": "30601b92-4f93-4e2c-a608-4dd98b023d32"
      },
      "source": [
        "categories = train_df['emotion'].unique() #examine how many categories are there\n",
        "print(categories)\n",
        "df.groupby('emotion').count() #examine how many samples are in each category"
      ],
      "id": "35828191-fd6a-4229-9eb7-0906d23a1916",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['anger' 'disgust' 'fear' 'neutral' 'happiness' 'surprise' 'sadness'\n",
            " 'contempt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contempt</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happiness</th>\n",
              "      <td>5696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>6868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           image\n",
              "emotion         \n",
              "anger        252\n",
              "contempt       9\n",
              "disgust      208\n",
              "fear          21\n",
              "happiness   5696\n",
              "neutral     6868\n",
              "sadness      268\n",
              "surprise     368"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64082aee-436f-4d1b-80c2-310a0604a106"
      },
      "source": [
        "import os\n",
        "os.mkdir('data/train')\n",
        "os.mkdir('data/valid')\n",
        "os.mkdir('data/test')\n",
        "for emotion in categories:\n",
        "    train_cat = 'data/train/'+emotion\n",
        "    valid_cat = 'data/valid/'+emotion\n",
        "    test_cat  = 'data/test/'+emotion\n",
        "    os.mkdir(train_cat)\n",
        "    os.mkdir(valid_cat)\n",
        "    os.mkdir(test_cat)"
      ],
      "id": "64082aee-436f-4d1b-80c2-310a0604a106",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9d4aad3-8e14-4f5d-b7fa-d41e0ce0e262"
      },
      "source": [
        "import shutil\n",
        "for index, row in train_df.iterrows():\n",
        "    file = row['image']\n",
        "    emotion = row['emotion']\n",
        "\n",
        "    dest_img_path = 'data/train/' + emotion + '/' + file\n",
        "    src_img_path = 'images/' + file\n",
        "\n",
        "    shutil.copy(src_img_path,dest_img_path)\n",
        "\n",
        "for index, row in valid_df.iterrows():\n",
        "    file = row['image']\n",
        "    emotion = row['emotion']\n",
        "\n",
        "    dest_img_path = 'data/valid/' + emotion + '/' + file\n",
        "    src_img_path = 'images/' + file\n",
        "\n",
        "    shutil.copy(src_img_path,dest_img_path)\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    file = row['image']\n",
        "    emotion = row['emotion']\n",
        "\n",
        "    dest_img_path = 'data/test/' + emotion + '/' + file\n",
        "    src_img_path = 'images/' + file\n",
        "\n",
        "    shutil.copy(src_img_path,dest_img_path)"
      ],
      "id": "c9d4aad3-8e14-4f5d-b7fa-d41e0ce0e262",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71c11061-0abe-4656-bfdf-d65f4584840b"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "img_h, img_w = 224, 224\n",
        "\n",
        "# this is the augmentation configuration I used for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.01,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='constant')\n",
        "\n",
        "# this is the augmentation configuration I used for testing:\n",
        "# only rescaling\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in+\n",
        "\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train/',  # this is the target directory\n",
        "        target_size=(img_h, img_w),  # all images will be resized to 224x224\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  #\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "        'data/valid/',\n",
        "        target_size=(img_h, img_w),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "id": "71c11061-0abe-4656-bfdf-d65f4584840b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eea7208"
      },
      "source": [
        "print(train_df.size, valid_df.size)"
      ],
      "id": "2eea7208",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f1b7682-625a-4f72-8124-d9af41409109",
        "outputId": "05852da4-62e8-4dce-c005-b819195af770"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "#Load the VGG model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3))\n",
        "base_model.summary()"
      ],
      "id": "0f1b7682-625a-4f72-8124-d9af41409109",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eb65b9f-7916-4b37-a7fb-770ab5fce490",
        "outputId": "518f31dd-e18f-4998-cfde-7142e7ae4874"
      },
      "source": [
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in base_model.layers:\n",
        "    print(layer, layer.trainable)\n"
      ],
      "id": "6eb65b9f-7916-4b37-a7fb-770ab5fce490",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f06cab623d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca89fd00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca8bc790> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f06ca8bc4c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca044c10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca044cd0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f06ca044fa0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca04ff40> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca057cd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06ca04be20> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f06ca057ca0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06c9feb670> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06c9feb1c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06c9fe33d0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f06c9febb50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06c9ff2520> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06c9fe56a0> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f06c9ff4730> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f06ca003970> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2678e2db-58b2-4ae5-a453-4922097b4365"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.utils.vis_utils import plot_model\n",
        "def define_model(base_model, num_cat):\n",
        "    inputs1 = Input(shape=(None, None, 3,))\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the vgg convolutional base model\n",
        "    model.add(base_model)\n",
        "\n",
        "    # Add new layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_cat, activation='softmax'))\n",
        "\n",
        "    # tie it together\n",
        "    #model = Model(inputs=inputs1, outputs=output)\n",
        "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "    # summarize model\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='mode.png', show_shapes=True)\n",
        "    return model"
      ],
      "id": "2678e2db-58b2-4ae5-a453-4922097b4365",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cb9149-54b6-46a3-bca9-582fd72a312e"
      },
      "source": [
        "model = define_model(base_model, 8)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "id": "08cb9149-54b6-46a3-bca9-582fd72a312e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "809a272b-b482-4d52-9e14-1202f2b8ade2"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(train_generator.classes)\n",
        "max_val = float(max(counter.values()))\n",
        "class_weights = {class_id : np.minimum(max_val/num_images,3) for class_id, num_images in counter.items()}\n",
        "print(class_weights)"
      ],
      "id": "809a272b-b482-4d52-9e14-1202f2b8ade2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a25bcf46-7a8e-4e01-bfe3-a341c99b811d"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "nb_train_samples = train_df.size\n",
        "nb_validation_samples = valid_df.size\n",
        "epochs=10\n",
        "print(nb_train_samples, nb_validation_samples)\n",
        "filepath=\"toy-model_1-epoch-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto',period=1)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n"
      ],
      "id": "a25bcf46-7a8e-4e01-bfe3-a341c99b811d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f691705b"
      },
      "source": [
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(train_generator.n/batch_size),\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=int(validation_generator.n/batch_size),\n",
        "        callbacks=callbacks_list,\n",
        "        class_weight=class_weights)\n",
        "\n",
        "model.save('toy_model1.h5')"
      ],
      "id": "f691705b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "587272b9",
        "outputId": "f9dee5bc-7d90-4a39-c17a-213788e602b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "id": "587272b9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e67d58381372>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdc07f3"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=\"data/test/\",\n",
        "    target_size=(img_h, img_w),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,\n",
        "                                steps=STEP_SIZE_TEST,\n",
        "                                verbose=1)\n",
        "\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "id": "5cdc07f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7acef3e9"
      },
      "source": [
        "\n",
        "\n",
        "filenames= [i.split('/')[1] for i in test_generator.filenames]\n",
        "results=pd.DataFrame({\"image\":filenames,\n",
        "                      \"emotion\":predictions})\n",
        "results.to_csv(\"results.csv\",index=False)\n",
        "test_df.to_csv(\"ground_truth.csv\")\n",
        "\n"
      ],
      "id": "7acef3e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71497026"
      },
      "source": [
        "result_test_merged = pd.merge(results, test_df, left_on=['image'],\n",
        "              right_on=['image'],\n",
        "              how='inner')\n",
        "compare=result_test_merged['emotion_x']==result_test_merged['emotion_y']\n",
        "acc = sum(compare)/len(compare)\n",
        "acc"
      ],
      "id": "71497026",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert model to TensorFlow Lite"
      ],
      "metadata": {
        "id": "fjcO8P6b8tpI"
      },
      "id": "fjcO8P6b8tpI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89e124a9"
      },
      "source": [
        "import tensorflow as tf\n",
        "keras_model = tf.keras.models.load_model(\"toy_model1.h5\")\n",
        "converter =  (keras_model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "id": "89e124a9",
      "execution_count": null,
      "outputs": []
    }
  ]
}